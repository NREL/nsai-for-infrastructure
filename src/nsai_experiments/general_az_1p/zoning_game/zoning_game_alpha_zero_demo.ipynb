{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d34cddc4",
   "metadata": {},
   "source": [
    "# Zoning Game AlphaZero Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b005e1",
   "metadata": {},
   "source": [
    "## Individually construct bits and pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e41415c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 1\n",
    "\n",
    "from nsai_experiments.general_az_1p.utils import disable_numpy_multithreading, use_deterministic_cuda\n",
    "disable_numpy_multithreading()\n",
    "use_deterministic_cuda()\n",
    "\n",
    "import copy\n",
    "\n",
    "# we have to imports a bit oddly to get autoreload to work\n",
    "%aimport nsai_experiments.general_az_1p.game\n",
    "Game = nsai_experiments.general_az_1p.game.Game\n",
    "%aimport nsai_experiments.general_az_1p.policy_value_net\n",
    "PolicyValueNet = nsai_experiments.general_az_1p.policy_value_net.PolicyValueNet\n",
    "%aimport nsai_experiments.general_az_1p.agent\n",
    "Agent = nsai_experiments.general_az_1p.agent.Agent\n",
    "\n",
    "%aimport nsai_experiments.general_az_1p.zoning_game.zoning_game_az_impl\n",
    "ZoningGameGame = nsai_experiments.general_az_1p.zoning_game.zoning_game_az_impl.ZoningGameGame\n",
    "%aimport nsai_experiments.general_az_1p.zoning_game.zoning_game_az_impl\n",
    "ZoningGamePolicyValueNet = nsai_experiments.general_az_1p.zoning_game.zoning_game_az_impl.ZoningGamePolicyValueNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97adf08",
   "metadata": {},
   "source": [
    "### The `Game`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ddfb6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tile grid:\n",
      "[[0 0 0 5 1 0]\n",
      " [0 4 0 0 0 0]\n",
      " [0 3 0 3 2 4]\n",
      " [0 0 0 0 0 0]\n",
      " [2 0 0 0 0 0]\n",
      " [0 0 0 0 3 1]]\n",
      "Tile queue (leftmost next): [1 4 2 1 5 2 3 3 2 3 1 1 1 4 2 2 1 5 5 2 1 5 3 2 5 1 0 0 0 0 0 0 0 0 0 0]\n",
      "where 0 = EMPTY, 1 = RESIDENTIAL, 2 = COMMERCIAL, 3 = INDUSTRIAL, 4 = DOWNTOWN, 5 = PARK.\n",
      "After 0 moves, current grid score is 3; terminated = False, truncated = False.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mygame = ZoningGameGame()\n",
    "assert isinstance(mygame, Game)\n",
    "mygame.reset_wrapper(seed=47)\n",
    "print(mygame.render().read())  # type: ignore[union-attr]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbc3da8",
   "metadata": {},
   "source": [
    "### The `PolicyValueNet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cd02249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from disk: ../../zoning_game/zg_data/create_policy_indiv_greedy__20000\n",
      "Done loading, shuffling, splitting data\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from nsai_experiments.zoning_game.notebook_utils import get_zg_data\n",
    "from nsai_experiments.zoning_game.zg_policy import create_policy_indiv_greedy\n",
    "\n",
    "torch.manual_seed(47)\n",
    "n_games = 20_000\n",
    "savedir = \"../../zoning_game/zg_data\"\n",
    "valid_frac = 0.15\n",
    "test_frac = 0.35\n",
    "\n",
    "states_tensor, values_tensor, moves_tensor = get_zg_data(create_policy_indiv_greedy, n_games = n_games, savedir = savedir)\n",
    "indices = torch.randperm(len(values_tensor))\n",
    "full_dataset_3 = torch.utils.data.TensorDataset(states_tensor[indices], moves_tensor[indices], values_tensor[indices])\n",
    "\n",
    "valid_size_3 = int(valid_frac * len(full_dataset_3))\n",
    "test_size_3 = int(test_frac * len(full_dataset_3))\n",
    "train_size_3 = len(full_dataset_3) - valid_size_3 - test_size_3\n",
    "train_dataset_3, valid_dataset_3, test_dataset_3 = torch.utils.data.random_split(full_dataset_3, [train_size_3, valid_size_3, test_size_3])\n",
    "print(\"Done loading, shuffling, splitting data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ae01ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network training will occur on device 'mps'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.02805594, 0.02738343, 0.02839885, 0.02788622, 0.0291001 ,\n",
       "        0.02763609, 0.02681519, 0.02864029, 0.02788756, 0.02838092,\n",
       "        0.02778699, 0.02877449, 0.02703443, 0.02906117, 0.02899825,\n",
       "        0.02776492, 0.02859806, 0.02702451, 0.02705516, 0.02807434,\n",
       "        0.02658405, 0.02678845, 0.02949526, 0.02644843, 0.02754996,\n",
       "        0.02703502, 0.02698193, 0.02768094, 0.02770268, 0.02843505,\n",
       "        0.02523457, 0.02692246, 0.02690465, 0.0284914 , 0.02925407,\n",
       "        0.02813419], dtype=float32),\n",
       " array(0.02830549, dtype=float32))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mynet = ZoningGamePolicyValueNet(random_seed=47)\n",
    "assert isinstance(mynet, PolicyValueNet)\n",
    "initial_obs = copy.deepcopy(mygame.obs)\n",
    "mynet.predict(initial_obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f12d2d",
   "metadata": {},
   "source": [
    "### The `Agent` and `MCTS`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7a9d5e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNG seeds are fully specified\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "logging.getLogger().setLevel(logging.WARN)  # TODO\n",
    "myagent = Agent(mygame, mynet, random_seeds={\"mcts\": 48, \"train\": 49, \"eval\": 50})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6eb4e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2166\n"
     ]
    }
   ],
   "source": [
    "real_examples = []\n",
    "for i in range(100):\n",
    "    res = myagent._play_for_examples(i, i+1, i+2)\n",
    "    real_examples.extend(res)\n",
    "print(len(real_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d47fd6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..evaluation done in 3.05 seconds\n",
      "Old network+MCTS average reward: 0.26, min: -0.13, max: 0.64, stdev: 0.20\n",
      "New network+MCTS average reward: 0.26, min: -0.13, max: 0.64, stdev: 0.20\n",
      "Old bare network average reward: 0.29, min: -0.04, max: 0.66, stdev: 0.20\n",
      "New bare network average reward: 0.29, min: -0.04, max: 0.66, stdev: 0.20\n",
      "New network won 0 and tied 20 out of 20 games (50.00% wins where ties are half wins)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oldagent = copy.deepcopy(myagent)\n",
    "myagent.pit(oldagent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ab5688",
   "metadata": {},
   "source": [
    "Does it perform better with some supervised pretraining?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e84d7b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2121.322389602661, 0.029563357558799908)\n"
     ]
    }
   ],
   "source": [
    "print(mynet.validate(valid_dataset_3, needs_reshape=False))\n",
    "# print(mynet.validate(real_examples, needs_reshape=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a62e8ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 212 batches of size 1024\n",
      "Validating with 64 batches of size 1024\n",
      "Epoch 1/10, Train Loss: 226.1332, Train Mean Max: 0.0916, Val Loss: 67.2739, Val Mean Max: 0.5250\n",
      "Epoch 2/10, Train Loss: 41.5601, Train Mean Max: 0.0719, Val Loss: 33.3013, Val Mean Max: 0.0802\n",
      "Epoch 3/10, Train Loss: 29.9196, Train Mean Max: 0.0701, Val Loss: 35.4818, Val Mean Max: 0.2063\n",
      "Epoch 4/10, Train Loss: 26.7608, Train Mean Max: 0.0721, Val Loss: 24.6123, Val Mean Max: 0.1887\n",
      "Epoch 5/10, Train Loss: 23.6819, Train Mean Max: 0.0786, Val Loss: 21.8252, Val Mean Max: 0.1003\n",
      "Epoch 6/10, Train Loss: 21.8756, Train Mean Max: 0.0959, Val Loss: 23.6329, Val Mean Max: 0.1294\n",
      "Epoch 7/10, Train Loss: 20.2668, Train Mean Max: 0.1186, Val Loss: 21.0380, Val Mean Max: 0.1770\n",
      "Epoch 8/10, Train Loss: 18.9612, Train Mean Max: 0.1509, Val Loss: 17.6440, Val Mean Max: 0.1900\n",
      "Epoch 9/10, Train Loss: 17.6445, Train Mean Max: 0.1874, Val Loss: 18.9868, Val Mean Max: 0.2482\n",
      "Epoch 10/10, Train Loss: 16.0391, Train Mean Max: 0.2345, Val Loss: 15.4496, Val Mean Max: 0.2713\n",
      "Training with 212 batches of size 1024\n",
      "Validating with 64 batches of size 1024\n",
      "Epoch 1/10, Train Loss: 92.3963, Train Mean Max: 0.1227, Val Loss: 20.8669, Val Mean Max: 0.2063\n",
      "Epoch 2/10, Train Loss: 16.8595, Train Mean Max: 0.1955, Val Loss: 17.2136, Val Mean Max: 0.2530\n",
      "Epoch 3/10, Train Loss: 15.0005, Train Mean Max: 0.2493, Val Loss: 15.6620, Val Mean Max: 0.2939\n",
      "Epoch 4/10, Train Loss: 13.9170, Train Mean Max: 0.2847, Val Loss: 18.8795, Val Mean Max: 0.3206\n",
      "Epoch 5/10, Train Loss: 13.5629, Train Mean Max: 0.3069, Val Loss: 14.7348, Val Mean Max: 0.3450\n",
      "Epoch 6/10, Train Loss: 12.8743, Train Mean Max: 0.3308, Val Loss: 13.7019, Val Mean Max: 0.3491\n",
      "Epoch 7/10, Train Loss: 12.3577, Train Mean Max: 0.3462, Val Loss: 13.3020, Val Mean Max: 0.3619\n",
      "Epoch 8/10, Train Loss: 11.9549, Train Mean Max: 0.3650, Val Loss: 13.1935, Val Mean Max: 0.3716\n",
      "Epoch 9/10, Train Loss: 11.7169, Train Mean Max: 0.3798, Val Loss: 14.6319, Val Mean Max: 0.4109\n",
      "Epoch 10/10, Train Loss: 11.3119, Train Mean Max: 0.3947, Val Loss: 12.9528, Val Mean Max: 0.4271\n",
      "Training with 212 batches of size 1024\n",
      "Validating with 64 batches of size 1024\n",
      "Epoch 1/10, Train Loss: 25.6796, Train Mean Max: 0.2936, Val Loss: 15.7473, Val Mean Max: 0.3525\n",
      "Epoch 2/10, Train Loss: 12.2557, Train Mean Max: 0.3585, Val Loss: 14.3284, Val Mean Max: 0.3940\n",
      "Epoch 3/10, Train Loss: 11.4757, Train Mean Max: 0.3893, Val Loss: 12.0209, Val Mean Max: 0.4100\n",
      "Epoch 4/10, Train Loss: 11.4105, Train Mean Max: 0.4018, Val Loss: 13.1596, Val Mean Max: 0.4027\n",
      "Epoch 5/10, Train Loss: 11.1507, Train Mean Max: 0.4083, Val Loss: 11.5604, Val Mean Max: 0.4390\n",
      "Epoch 6/10, Train Loss: 10.5450, Train Mean Max: 0.4203, Val Loss: 13.1459, Val Mean Max: 0.4407\n",
      "Epoch 7/10, Train Loss: 11.5043, Train Mean Max: 0.4171, Val Loss: 11.4062, Val Mean Max: 0.4572\n",
      "Epoch 8/10, Train Loss: 10.2974, Train Mean Max: 0.4299, Val Loss: 12.0875, Val Mean Max: 0.4576\n",
      "Epoch 9/10, Train Loss: 10.5776, Train Mean Max: 0.4314, Val Loss: 10.8007, Val Mean Max: 0.4367\n",
      "Epoch 10/10, Train Loss: 13.1908, Train Mean Max: 0.4153, Val Loss: 12.4824, Val Mean Max: 0.4618\n",
      "Training with 212 batches of size 1024\n",
      "Validating with 64 batches of size 1024\n",
      "Epoch 1/10, Train Loss: 29.2615, Train Mean Max: 0.1846, Val Loss: 13.8848, Val Mean Max: 0.2942\n",
      "Epoch 2/10, Train Loss: 11.9454, Train Mean Max: 0.3051, Val Loss: 12.0107, Val Mean Max: 0.3415\n",
      "Epoch 3/10, Train Loss: 11.5436, Train Mean Max: 0.3512, Val Loss: 12.1650, Val Mean Max: 0.3693\n",
      "Epoch 4/10, Train Loss: 10.6266, Train Mean Max: 0.3866, Val Loss: 16.3173, Val Mean Max: 0.4160\n",
      "Epoch 5/10, Train Loss: 10.2839, Train Mean Max: 0.4099, Val Loss: 12.0949, Val Mean Max: 0.4370\n",
      "Epoch 6/10, Train Loss: 10.2374, Train Mean Max: 0.4203, Val Loss: 10.4995, Val Mean Max: 0.4363\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mmynet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset_3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_dataset_3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneeds_reshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_all_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m;  \u001b[38;5;66;03m# takes a little while\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/JuliaProjects/S-NSAI/nsai_experiments/src/nsai_experiments/general_az_1p/zoning_game/zoning_game_az_impl.py:201\u001b[0m, in \u001b[0;36mZoningGamePolicyValueNet.train\u001b[0;34m(self, examples, val_dataset, needs_reshape, print_all_epochs)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# Validation phase\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m     val_loss, val_mean_max \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m     val_losses\u001b[38;5;241m.\u001b[39mappend(val_loss)\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m print_all_epochs \u001b[38;5;129;01mor\u001b[39;00m epoch \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m epoch \u001b[38;5;241m==\u001b[39m tp[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/JuliaProjects/S-NSAI/nsai_experiments/src/nsai_experiments/general_az_1p/zoning_game/zoning_game_az_impl.py:226\u001b[0m, in \u001b[0;36mZoningGamePolicyValueNet.validate_inner\u001b[0;34m(self, val_loader)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m inputs, targets_policy, targets_value \u001b[38;5;129;01min\u001b[39;00m val_loader:\n\u001b[0;32m--> 226\u001b[0m         inputs, targets_value, targets_policy \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mDEVICE), \u001b[43mtargets_value\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m, targets_policy\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mDEVICE)\n\u001b[1;32m    227\u001b[0m         outputs_policy, outputs_value \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[1;32m    228\u001b[0m         loss_value \u001b[38;5;241m=\u001b[39m criterion_value(outputs_value\u001b[38;5;241m.\u001b[39msqueeze(), targets_value)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    mynet.train(train_dataset_3, valid_dataset_3, needs_reshape=False, print_all_epochs=True);  # takes a little while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f235d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10.231495648622513, 0.4422969068400562)\n",
      "(1130.5799153645833, 0.36118146777153015)\n"
     ]
    }
   ],
   "source": [
    "print(mynet.validate(valid_dataset_3, needs_reshape=False))\n",
    "print(mynet.validate(real_examples, needs_reshape=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e73ab03",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mynet.validate(valid_dataset_3, needs_reshape=False))\n",
    "print(mynet.validate(real_examples, needs_reshape=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbc55f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.00171641, 0.06226806, 0.14863802, 0.01154106, 0.00627946,\n",
       "        0.19635542, 0.11545606, 0.001392  , 0.04622583, 0.0365124 ,\n",
       "        0.01825142, 0.03437214, 0.00270969, 0.00790704, 0.00148205,\n",
       "        0.00158032, 0.01038758, 0.01097031, 0.01023317, 0.00970493,\n",
       "        0.00760836, 0.00303479, 0.01117896, 0.08993824, 0.01089501,\n",
       "        0.00764156, 0.0113241 , 0.00556701, 0.00761443, 0.08500791,\n",
       "        0.00693498, 0.00597418, 0.00562198, 0.00591261, 0.00083107,\n",
       "        0.0009315 ], dtype=float32),\n",
       " array(1.9298165, dtype=float32))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mynet.predict(initial_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad85f8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..evaluation done in 14.31 seconds\n",
      "Old network+MCTS average reward: 0.34, min: -0.04, max: 0.74, stdev: 0.23\n",
      "New network+MCTS average reward: 0.44, min: 0.18, max: 0.85, stdev: 0.19\n",
      "Old bare network average reward: 0.30, min: 0.03, max: 0.75, stdev: 0.20\n",
      "New bare network average reward: 0.41, min: -0.03, max: 0.90, stdev: 0.23\n",
      "New network won 15 and tied 0 out of 20 games (75.00% wins where ties are half wins)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.75)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myagent.n_procs = -1\n",
    "myagent.pit(oldagent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fec1d650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..evaluation done in 13.23 seconds\n",
      "Old network+MCTS average reward: 0.34, min: -0.22, max: 0.97, stdev: 0.24\n",
      "New network+MCTS average reward: 0.44, min: 0.04, max: 0.93, stdev: 0.25\n",
      "Old bare network average reward: 0.31, min: -0.26, max: 0.95, stdev: 0.28\n",
      "New bare network average reward: 0.36, min: 0.02, max: 0.91, stdev: 0.22\n",
      "New network won 15 and tied 1 out of 20 games (77.50% wins where ties are half wins)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.775)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myagent.mcts_params[\"temperature\"] = 1/20.\n",
    "myagent.pit(oldagent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
